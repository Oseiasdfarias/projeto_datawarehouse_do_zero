<p align="center">
  <img height="50px" src="./utils/proj.png">
</p>

<p align="center">
  <img height="28" src="./utils/Data_Warehous.png"> &
  <img height="28" src="./utils/ETL.png">
</p>

<h3>Sum√°rio</h3>


<p id="roadmap"> 
  <ul>
    <li> <a href="#techs">Tecnologias</a></li>
    <li> <a href="#id1">  Descri√ß√£o do Projeto</a> </li>
    <li> <a href="#id2">  Explica√ß√£o do Workflow ETL</a> </li>
    <li> <a href="#id3">  Como executar o Projeto</a> </li>
  </ul>
</p>


<h3  id="techs">Tecnologias</h3>

<p align=center> <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54"> <img src="https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white"> <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white"> <img src="https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white"> <img src="https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white"> 
  </ul>
  <br>
</p>


# Projeto de Data Warehouse de Commodities



<p align="center">
  <img wigth="90%" src="./utils/diagram.svg">
</p>


<h3  id="id1">Descri√ß√£o do Projeto</h3>

---

Voc√™ sabe quanto sua empresa vendeu ontem? Se precisar de mais de 3 segundos para responder, o workshop de hoje √© ideal para voc√™!

Nosso objetivo √© desenvolver um Data Warehouse (DW) que armazene e analise dados de commodities, empregando uma arquitetura moderna de ETL (Extract, Transform, Load). Este projeto abrange v√°rias etapas essenciais:

1. **Documenta√ß√£o do DBT**:
   - Cria√ß√£o de uma documenta√ß√£o completa e detalhada para facilitar o entendimento e a manuten√ß√£o do processo de ETL, garantindo a transpar√™ncia e a rastreabilidade dos dados.

2. **Dashboard Interativo**:
   - Desenvolvimento de um painel interativo usando Streamlit, que permite a visualiza√ß√£o din√¢mica dos dados de commodities, facilitando a tomada de decis√µes baseada em dados precisos e atualizados.

3. **Parte de Extract_Load**:
   - Implementa√ß√£o de um processo de extra√ß√£o de dados diretamente de uma API. Esses dados s√£o ent√£o carregados diretamente em um banco de dados PostgreSQL, garantindo que a informa√ß√£o seja centralizada e facilmente acess√≠vel para an√°lise.

4. **Parte de Seed**:
   - Utiliza√ß√£o de seeds do DBT para carregar dados hist√≥ricos e transacionais de commodities a partir de arquivos CSV. Esse processo garante que todos os dados relevantes sejam inclu√≠dos e estruturados corretamente no Data Warehouse.

5. **Models**:
   - Defini√ß√£o das transforma√ß√µes de dados utilizando o DBT. Isso inclui a cria√ß√£o de tabelas de staging, que servem como intermedi√°rias, e de datamarts, que s√£o espec√≠ficas para an√°lises detalhadas e relat√≥rios. Estas transforma√ß√µes garantem que os dados estejam limpos, consolidados e prontos para an√°lise.

6. **Implementa√ß√£o do Dashboard em Streamlit**:
   - Desenvolvimento de um dashboard com Streamlit que apresenta os dados de commodities de forma clara e interativa. Este dashboard permite aos usu√°rios visualizar tend√™ncias, realizar compara√ß√µes e obter insights valiosos para o neg√≥cio.

Este projeto √© fundamental para qualquer empresa que precise de uma an√°lise precisa e r√°pida de seus dados de vendas e movimenta√ß√µes de commodities, promovendo uma cultura de decis√µes orientadas por dados. 

---

Com essa abordagem, sua empresa poder√° responder perguntas cr√≠ticas sobre vendas e movimenta√ß√µes de commodities de forma r√°pida e eficaz, aumentando a efici√™ncia operacional e a competitividade no mercado.


<h3  id="id2">Explica√ß√£o do Workflow ETL</h3>


1. **Extra√ß√£o**:
    - **Importa√ß√£o das bibliotecas necess√°rias**: Importamos as bibliotecas `yfinance`, `pandas` e `sqlalchemy`.
    - **Defini√ß√£o da fun√ß√£o buscar_dados_commodities**: Definimos uma fun√ß√£o para buscar os dados de um s√≠mbolo espec√≠fico de commodities.
    - **Busca de dados das commodities**: Utilizamos a fun√ß√£o `buscar_dados_commodities` para obter os dados de cada commodity.

2. **Transforma√ß√£o**:
    - **Defini√ß√£o da fun√ß√£o buscar_todos_dados_commodities**: Definimos uma fun√ß√£o para buscar os dados de todos os s√≠mbolos de commodities e concaten√°-los em um √∫nico DataFrame.
    - **Concatenar dados de todas as commodities**: Utilizamos a fun√ß√£o `buscar_todos_dados_commodities` para concatenar todos os dados em um √∫nico DataFrame.

3. **Carga**:
    - **Defini√ß√£o da fun√ß√£o salvar_no_postgres**: Definimos uma fun√ß√£o para salvar o DataFrame resultante no banco de dados PostgreSQL.
    - **Salvar dados no banco de dados PostgreSQL**: Utilizamos a fun√ß√£o `salvar_no_postgres` para salvar o DataFrame final no banco de dados PostgreSQL.

Este diagrama segue o estilo ETL, destacando claramente as etapas de Extra√ß√£o, Transforma√ß√£o e Carga.


```mermaid
graph TD;
    subgraph Extract_Load
        A1[buscar_dados_commodities] --> B1[buscar_todos_dados_commodities]
        B1 --> C1[carregar_dados_no_postgres]
    end

    subgraph Transform
        D1[stg_commodities.sql] --> E1[stg_movimentacao_commodities.sql]
        E1 --> F1[dm_commodities.sql]
    end

    A[API de Commodities] -->|Extrai Dados| Extract_Load
    Extract_Load -->|Carrega Dados| C[PostgreSQL]
    C -->|Armazena Dados| D[Data Warehouse]
    Data_Warehouse -->|Transforma Dados| Transform
    Transform -->|Cria Views| F[Dashboard Streamlit]

```

---

<h3  id="id3">Como executar o Projeto</h3>


Para usar o projeto voc√™ deve criar um ambiente virtual do Python, para isso voc√™ deve ter instalado em seu computador o [pyenv](https://github.com/pyenv/pyenv), [virtualenv](https://virtualenv.pypa.io/en/latest/installation.html) ou [poetry](https://python-poetry.org/docs/).

Obs: Copie apenas o texto, sem o simbolo `‚ùØ`.

```bash
# Ativando a virtual env
‚ùØ poetry shell

# instalando as depend√™ncias
‚ùØ poetry install
```


```bash
‚ùØ python -m venv .venv

# Ativando o ambiente no Windows
‚ùØ source .venv/bin/activate

# Ativando o ambiente no Linux e Mac
‚ùØ source .venv/bin/activate

‚ùØ pip install -r requirements.txt
```

Agora √© necess√°rio usar um banco de dados Postgres, uma boa forma de iniciar seus trabalhos com banco de dados √© usando o [Render](https://docs.render.com/databases), com ele voc√™ cria um banco de dados postgres em alguns clicque, para criar o seu banco de dados usando essa plataforma assista a esse [Tutorial](https://www.youtube.com/watch?v=icpPqD0tjLg)


Ap√≥s criar o banco de dados postgres voc√™ deve criar um arquivo `.env` que conterar o seguintes campos:


```bash
DB_HOST_PROD=dpg-cpke84q0si5c73cp9uog-a.virginia-postgres.render.com
DB_PORT_PROD=5432
DB_NAME_PROD=nome_banco_de_dados_criado
DB_USER_PROD=nome_do_usuario_do_banco_de_dados_criado
DB_PASS_PROD=senha_do_banco_de_dados
DB_SCHEMA_PROD=public
DB_THREADS_PROD=1
DB_TYPE_PROD=postgres
DBT_PROFILES_DIR=../
```

mude apenas os campos, `DB_NAME_PROD`, `DB_USER_PROD`, `DB_PASS_PROD`.

# Executando o projeto

Ap√≥s os procedimentos acima terem sido feitos, o proximo passo √© executar o projeto, para isso inicia-se executando o `Extract` e `Load` que que foi desenvolvido no c√≥digo `extract_load.py` que est√° dentro da pasta `src`, para executa-lo, basta roda o seguinte comando no terminal.

```bash
‚ùØ python src/extract_load.py
```

Com isso, o banco de dados postgres deve est√° com as seguintes tabelas criadas:

|Tables| campos|
|---|---|
|commodities|date, symbol, action, quantity|
|movimentacao_commodities|Date, Close, simbolo|


Caso n√£o tenha ocorrido nenhum erro anteriormente, agora deve-se executar o comando que vai realizar o `transform`, para isso vamos usar o `dbt` para rodar as transforma√ß√µes contidas nos arquivos `sql` do projeto:

Antes de realizar o transforma√ß√£o, voc√™ pode verificar se o `dbt` consegue se comunicar com o banco de dados postgres, para isso entre para dentro da pasta `datawarehouse` pelo terminal e rodo o seguinte comando:


```bash
‚ùØ dbt debug
```

caso tenha a seguinte mensagem no terminal, seguinifica que o `dbt` est√° se conectando ao banco de dados postgres:


```bash
.
.
.
23:25:46    retries: 1
23:25:46  Registered adapter: postgres=1.8.1
23:25:47    Connection test: [OK connection ok]

23:25:47  All checks passed!
```

Com isso √© possivel realizar a transforma√ß√£o dos dados, basta executar o seguinte comando dentro da pasta `datawarehouse` pelo termianl:


```bash
 ‚ùØ dbt run
```

Ao acessar o banco de dados, em `views` deve ter os seguintes views, `dm_commodities`, `stg_commodities`, `stg_movimentacao_commodities`.


|Views| campos|
|---|---|
|dm_commodities|data,simbolo,valor_fechamento, acao, quantidade,valor, ganho|
|stg_commodities|data, valor_fechamento, simbolo|
|stg_movimentacao_commodities|data, simbolo, acao, quantidade|


---

# Certificado



<p align="center">
  <img wigth="90%" src="./utils/Data Warehouse com Python, SQL e dbt-core.jpg">
</p>



## Em desenvolvimento ...



<h3  id="id9">üé• Rede Social</h3>

<p align=center> <a href="https://oseiasfarias.info"><img src="https://img.shields.io/badge/Portf√≥lio-%230077B5.svg?style=for-the-badge&logoColor=white"></a> <a href="https://www.linkedin.com/in/oseiasfarias/"><img src="https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white"></a>
<a href="https://oseiasfarias.medium.com"><img src="https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white"></a>
<a href="https://www.kaggle.com/osiasdfarias"><img src="https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white"></a>
</p>